{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WgAFsIKOzFR"
      },
      "source": [
        "# import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "U4TFvFyFOtQS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import Sequential\n",
        "import keras.layers as layers\n",
        "import keras.backend as K\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgcmwGowP7gd"
      },
      "source": [
        "# import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R2DBM4FlP5-J"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv('https://raw.githubusercontent.com/Sebercheres/UTS-DL/main/dataset/X_train.csv')\n",
        "X_val = pd.read_csv('https://raw.githubusercontent.com/Sebercheres/UTS-DL/main/dataset/X_val.csv')\n",
        "X_test = pd.read_csv('https://raw.githubusercontent.com/Sebercheres/UTS-DL/main/dataset/X_test.csv')\n",
        "\n",
        "y_train = pd.read_csv('https://raw.githubusercontent.com/Sebercheres/UTS-DL/main/dataset/y_train.csv')\n",
        "y_val = pd.read_csv('https://raw.githubusercontent.com/Sebercheres/UTS-DL/main/dataset/y_val.csv')\n",
        "y_test = pd.read_csv('https://raw.githubusercontent.com/Sebercheres/UTS-DL/main/dataset/y_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L2x70c2RQSbz",
        "outputId": "0654903e-ed21-4f77-fdc5-c5738b45e640"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a6991fa0-734f-4b51-8991-fa747267ddee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.108288</td>\n",
              "      <td>0.334538</td>\n",
              "      <td>-0.928804</td>\n",
              "      <td>0.568671</td>\n",
              "      <td>0.833502</td>\n",
              "      <td>-0.657141</td>\n",
              "      <td>0.506799</td>\n",
              "      <td>-0.564233</td>\n",
              "      <td>0.771240</td>\n",
              "      <td>-0.362660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.682776</td>\n",
              "      <td>0.791829</td>\n",
              "      <td>-0.753517</td>\n",
              "      <td>-1.284149</td>\n",
              "      <td>0.895069</td>\n",
              "      <td>-0.795165</td>\n",
              "      <td>0.878750</td>\n",
              "      <td>-0.792463</td>\n",
              "      <td>-0.938867</td>\n",
              "      <td>0.682620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.380328</td>\n",
              "      <td>0.984271</td>\n",
              "      <td>-0.313804</td>\n",
              "      <td>0.853838</td>\n",
              "      <td>0.550795</td>\n",
              "      <td>-0.904042</td>\n",
              "      <td>0.958895</td>\n",
              "      <td>0.523307</td>\n",
              "      <td>-0.846885</td>\n",
              "      <td>-0.077131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.682534</td>\n",
              "      <td>0.662424</td>\n",
              "      <td>1.182869</td>\n",
              "      <td>-0.746355</td>\n",
              "      <td>0.846742</td>\n",
              "      <td>1.481897</td>\n",
              "      <td>0.173655</td>\n",
              "      <td>0.840533</td>\n",
              "      <td>-0.489766</td>\n",
              "      <td>-0.656951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.459707</td>\n",
              "      <td>1.753709</td>\n",
              "      <td>-3.044087</td>\n",
              "      <td>1.822702</td>\n",
              "      <td>-3.255496</td>\n",
              "      <td>-1.468134</td>\n",
              "      <td>-3.010396</td>\n",
              "      <td>1.930334</td>\n",
              "      <td>-1.587531</td>\n",
              "      <td>-2.640146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6991fa0-734f-4b51-8991-fa747267ddee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6991fa0-734f-4b51-8991-fa747267ddee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6991fa0-734f-4b51-8991-fa747267ddee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0  1.108288  0.334538 -0.928804  0.568671  0.833502 -0.657141  0.506799   \n",
              "1 -0.682776  0.791829 -0.753517 -1.284149  0.895069 -0.795165  0.878750   \n",
              "2 -0.380328  0.984271 -0.313804  0.853838  0.550795 -0.904042  0.958895   \n",
              "3 -0.682534  0.662424  1.182869 -0.746355  0.846742  1.481897  0.173655   \n",
              "4 -1.459707  1.753709 -3.044087  1.822702 -3.255496 -1.468134 -3.010396   \n",
              "\n",
              "         V8        V9       V10  \n",
              "0 -0.564233  0.771240 -0.362660  \n",
              "1 -0.792463 -0.938867  0.682620  \n",
              "2  0.523307 -0.846885 -0.077131  \n",
              "3  0.840533 -0.489766 -0.656951  \n",
              "4  1.930334 -1.587531 -2.640146  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOXUtH8iQUHO",
        "outputId": "6783b53a-82d5-425a-f4ba-8bd74fed9901"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28481, 10)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lLX8snnQYr2",
        "outputId": "a4e4031f-4b5c-49c6-fa9a-4e389217f588"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28481, 10)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YDePlRPQi-i"
      },
      "source": [
        "> as we agree that the val and test is 10%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob6EwVWwQnK-"
      },
      "source": [
        "# base model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMmZJxxcRZZP"
      },
      "source": [
        "> for the base model the architecture will be (𝒏, 𝟐 × 𝒏, 𝟐 × 𝒏, 𝒏𝒖𝒎_𝒄𝒍𝒂𝒔𝒔) where n is input layer which means how many features there are which is 10 and num_class which is 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h2nI0tDvRYRU"
      },
      "outputs": [],
      "source": [
        "n = len(X_train.columns)\n",
        "num_class = len(y_train.target.unique()) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z-2o0Gu5SYuT"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "base_model = Sequential()\n",
        "base_model.add(layers.Dense(2 * n, input_shape = (n,)))\n",
        "base_model.add(layers.Activation('relu'))\n",
        "base_model.add(layers.Dense(2 * n))\n",
        "base_model.add(layers.Activation('relu'))\n",
        "base_model.add(layers.Dense(num_class))\n",
        "base_model.add(layers.Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB5XErz4aSj7"
      },
      "source": [
        "> as we are going to use binary cross entropy the class will be only 1 with probability of 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVPq8jUeVCxK",
        "outputId": "6f57ef67-d5e3-4bb7-fdd8-9374f01fd85d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                220       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 20)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 661\n",
            "Trainable params: 661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DnPr3UwVL3G"
      },
      "source": [
        "> from the first dense we can see that the input will be 10 and the dense layer will be 20 as it suggest in the question but it will add 20 for its bias and also the next and next one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99cl6it3Vs6n"
      },
      "source": [
        "> now we are going to compile the model the loss will be binary crossentropy for the epoch will be 5 and the optimizer will be Adam as it is one of the fastest and more accurate and the metrics will be accuracy and f1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "km89utzlXUgJ"
      },
      "outputs": [],
      "source": [
        "def get_f1(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LCjyTgF0VbUl"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "metrics = [get_f1, 'accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8FobEVbtWkDg"
      },
      "outputs": [],
      "source": [
        "base_model.compile(loss = loss, optimizer = optimizer, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DEJuFD2Xfcs",
        "outputId": "9d1aeabb-3ab1-4b18-f5b9-627aae380b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7733/7733 [==============================] - 41s 5ms/step - loss: 0.3961 - get_f1: 0.0502 - accuracy: 0.9129 - val_loss: 0.1567 - val_get_f1: 0.0123 - val_accuracy: 0.9979\n",
            "Epoch 2/5\n",
            "7733/7733 [==============================] - 28s 4ms/step - loss: 0.1526 - get_f1: 0.5564 - accuracy: 0.9592 - val_loss: 0.0534 - val_get_f1: 0.0359 - val_accuracy: 0.9952\n",
            "Epoch 3/5\n",
            "7733/7733 [==============================] - 29s 4ms/step - loss: 0.0937 - get_f1: 0.7382 - accuracy: 0.9759 - val_loss: 0.0338 - val_get_f1: 0.0382 - val_accuracy: 0.9958\n",
            "Epoch 4/5\n",
            "7733/7733 [==============================] - 29s 4ms/step - loss: 0.0789 - get_f1: 0.7689 - accuracy: 0.9793 - val_loss: 0.0282 - val_get_f1: 0.0385 - val_accuracy: 0.9959\n",
            "Epoch 5/5\n",
            "7733/7733 [==============================] - 29s 4ms/step - loss: 0.0725 - get_f1: 0.7725 - accuracy: 0.9804 - val_loss: 0.0256 - val_get_f1: 0.0404 - val_accuracy: 0.9957\n"
          ]
        }
      ],
      "source": [
        "base_hist = base_model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data = (X_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikFeqsLtbe0r"
      },
      "source": [
        "> because of the data that was given we cannot do a lot as the data is very much imbalanced it can have a really got accuracy but a bad f1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSDfPa6lbdAA"
      },
      "source": [
        "# modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33g7gKvmbeaB"
      },
      "source": [
        "> for this one im going to make a DNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt1hnNFIcxX7"
      },
      "source": [
        "> to deal with vanishing gradient im going to use elu as activation and using batch norm with he kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XxI2vgVmcPEz"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(keras.Input(shape=(n,)))\n",
        "for _ in range(10):\n",
        "  model.add(layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "  model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qLfXbNngodw",
        "outputId": "cccae853-1496-4cef-923d-15680bc97eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 300)               3300      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 300)              1200      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 300)               90300     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 301       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 828,301\n",
            "Trainable params: 822,301\n",
            "Non-trainable params: 6,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzXw8S43gqga",
        "outputId": "abcf635f-b5c4-4563-9a48-8e4deacae450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7733/7733 [==============================] - 90s 11ms/step - loss: 0.1596 - get_f1: 0.7992 - accuracy: 0.9629 - val_loss: 0.0419 - val_get_f1: 0.0412 - val_accuracy: 0.9968\n",
            "Epoch 2/5\n",
            "7733/7733 [==============================] - 85s 11ms/step - loss: 0.0662 - get_f1: 0.8529 - accuracy: 0.9865 - val_loss: 0.0311 - val_get_f1: 0.0417 - val_accuracy: 0.9961\n",
            "Epoch 3/5\n",
            "7733/7733 [==============================] - 85s 11ms/step - loss: 0.0421 - get_f1: 0.8595 - accuracy: 0.9892 - val_loss: 0.0232 - val_get_f1: 0.0417 - val_accuracy: 0.9959\n",
            "Epoch 4/5\n",
            "7733/7733 [==============================] - 83s 11ms/step - loss: 0.0329 - get_f1: 0.8618 - accuracy: 0.9904 - val_loss: 0.0201 - val_get_f1: 0.0413 - val_accuracy: 0.9953\n",
            "Epoch 5/5\n",
            "7733/7733 [==============================] - 87s 11ms/step - loss: 0.0281 - get_f1: 0.8675 - accuracy: 0.9912 - val_loss: 0.0171 - val_get_f1: 0.0424 - val_accuracy: 0.9956\n"
          ]
        }
      ],
      "source": [
        "model_hist = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data = (X_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vViAlfrWjOou"
      },
      "source": [
        "> even if the accuracy isnt really improve that much we get an improvement a little bit in the f1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBLGf-f_jVYL"
      },
      "source": [
        "# evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJI2Zdf5jWpS",
        "outputId": "80f7277d-597c-4810-97a1-ab8dd28ac395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 3s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "f = lambda x: 1 if x > 0.5 else 0\n",
        "y_pred = np.array(list(map(f, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LeUpsINjy0-",
        "outputId": "79e14fcd-91ec-4f85-b8ad-4770cec3f0a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28432\n",
            "           1       0.26      0.84      0.39        49\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.63      0.92      0.70     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOHujgxhlUD_"
      },
      "source": [
        "> the recall of the model is very goog but the f1-score isn't really that great"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "o7-sl6TIj6aD",
        "outputId": "e443d7b2-2ea9-4d56-f5c9-641c51baca72"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g', ax=ax)\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rRCaU6_lKh_"
      },
      "source": [
        "> it only missed 8 and predict it to 0 but it predict a lot of 0 as 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlRw4F9Nlcmj"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUwQJcAqlezU"
      },
      "source": [
        "> the data is very much difficult to handle as the imbalance is over the top even if we have a really good accuracy we will have a bad f1-score my model have a 40% of f1-score which is not really that bad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> my model is better than the baseline because my model is categorize as DNN which can perform much better than a MLP. we can also see that the f1-score of the model also improve about the accuracy we cannot say anything as if the model just predict all to be 0 than the accuracy will also be high as the data that was given is very imbalance and need a lot of preprocessing"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
